1
00:00:09,147 --> 00:00:10,528
Hey listeners, this is Danielle.

2
00:00:10,888 --> 00:00:11,409
And Shelley.

3
00:00:12,149 --> 00:00:14,792
Shelley is a radical Dravidian and racial equity activist.

4
00:00:15,092 --> 00:00:17,834
And Danielle is a community mobilizer and changemaker.

5
00:00:18,475 --> 00:00:20,176
And this is the Medford Bites podcast.

6
00:00:21,457 --> 00:00:28,363
Every two weeks, we chew on the issues facing Medford and deliver bites of information about the city by lifting the expertise of our guests.

7
00:00:29,203 --> 00:00:32,246
Join us in discussion about what you hope for the future of Medford.

8
00:00:32,666 --> 00:00:34,728
And as always, tell us where you like to eat.

9
00:00:44,284 --> 00:00:46,126
Thank you both for being here with us today.

10
00:00:46,146 --> 00:00:51,530
If you don't mind just starting by introducing yourselves with your name and pronouns and just a bit about who you are.

11
00:00:53,111 --> 00:00:53,291
Great.

12
00:00:53,371 --> 00:00:54,252
I'm Jean Zotter.

13
00:00:54,272 --> 00:00:57,074
I use she, her pronouns.

14
00:00:58,035 --> 00:01:02,738
And I'm part of a grassroots group in Medford called Medford People Power.

15
00:01:03,619 --> 00:01:05,581
And we're affiliated with the ACLU.

16
00:01:06,421 --> 00:01:11,485
And we work on protecting civil rights, civil liberties in Medford, Massachusetts.

17
00:01:12,226 --> 00:01:13,787
And I can say more about them later.

18
00:01:17,273 --> 00:01:17,513
Yeah.

19
00:01:19,534 --> 00:01:33,541
Great, and I'm Kit Collins, my pronouns are she, her, hers, and I'm a Medford City Councilor and I was a co-sponsor of the ordinance project that we worked on with Jean and Medford People Power this past year.

20
00:01:35,853 --> 00:01:36,333
Thank you both.

21
00:01:36,373 --> 00:01:40,714
So we will talk a little bit more about the topic of sea crops.

22
00:01:40,734 --> 00:01:45,576
We'll get into a little bit more about what that means and how you both worked on that.

23
00:01:45,696 --> 00:01:50,097
But before we get into it, I want to ask you both the question that we ask everybody on the podcast.

24
00:01:50,197 --> 00:01:53,237
Kit, you've answered this before, but maybe you have a different answer this time.

25
00:01:53,257 --> 00:01:57,959
And the question is, what is your favorite place to eat in Medford and what do you like to eat there?

26
00:01:59,867 --> 00:02:03,248
Well, I knew you were going to ask this question, so I've been thinking about it.

27
00:02:04,749 --> 00:02:06,729
My favorite place is Goldilocks.

28
00:02:06,769 --> 00:02:12,912
I think I have to do a shout out to the, at least by volume, we eat there the most at my family.

29
00:02:13,812 --> 00:02:21,875
And we get a dozen bagels, which I put in the freezer and we eat over a couple of weeks, but I love their rosemary sea salt bagel.

30
00:02:23,115 --> 00:02:24,756
Just ate one this morning, yeah.

31
00:02:26,396 --> 00:02:27,377
So, thanks.

32
00:02:31,145 --> 00:02:33,106
As for me, it's always a hard question.

33
00:02:33,126 --> 00:02:37,509
I feel like I have to bounce between my two South Medford faves.

34
00:02:37,549 --> 00:02:42,432
Last time I was on the podcast, I had to say Colette, because it's right down the street from my house.

35
00:02:42,612 --> 00:02:53,339
But this time of year has me thinking about Oasis, like a perfect summer evening is to stop by the tough school and then go get a nice dinner at Oasis and sit outside.

36
00:02:53,399 --> 00:02:55,421
So that's my story and I'm sticking to it.

37
00:02:56,964 --> 00:02:57,445
I love it.

38
00:02:57,965 --> 00:02:58,606
Sounds great.

39
00:03:00,047 --> 00:03:01,688
So happy to jump in.

40
00:03:01,949 --> 00:03:10,877
We thought we might ask you to start by teaching us about sort of the basics of CCOPS and just giving us sort of the framework and a little bit about the history.

41
00:03:12,263 --> 00:03:15,425
Sure, so I'll dive in from the community side.

42
00:03:16,646 --> 00:03:20,749
CCOP stands for Community Control Over Public Surveillance.

43
00:03:21,849 --> 00:03:40,842
And it's basically a legal mechanism for the city to present what surveillance technology they plan to use in the city at a city council hearing and for the public to provide input into whether we think that technology makes sense for our city.

44
00:03:43,067 --> 00:03:47,556
how we think the technology should be used, especially on Medford residents.

45
00:03:49,356 --> 00:03:58,360
and input into how they'll report or sort of tracking over time how the technology is used.

46
00:03:59,020 --> 00:04:02,201
So it doesn't bar any technology.

47
00:04:03,141 --> 00:04:12,605
It's really just setting up a public input process to make the use of technology transparent and use the technology accountable to Medford residents.

48
00:04:14,666 --> 00:04:20,710
Why this matters is that there is more and more technology created every day.

49
00:04:21,630 --> 00:04:36,040
Artificial intelligence is in the news now, but there's other things like just even location data that's on your phone that Google can sell to brokers who then can sell it to police departments.

50
00:04:36,740 --> 00:04:39,482
They have these huge pieces of data on you.

51
00:04:39,562 --> 00:04:40,983
There's other kinds of technology.

52
00:04:41,603 --> 00:04:53,247
such as a stingray which is not used in Medford but is used by other police departments in the state where they mimic cell phone towers and can get your location data on track where you are.

53
00:04:53,927 --> 00:04:57,428
So there's a lot of this technology emerging every year.

54
00:04:58,468 --> 00:05:05,872
And it's not regulated, really, I think, maybe people hear the most about facial recognition technology.

55
00:05:06,552 --> 00:05:15,136
But, and so that is one piece, but there's other types of technology and we have very little state law or federal law that govern it.

56
00:05:17,357 --> 00:05:22,198
It's used a lot by police departments, but also by other, like, school departments.

57
00:05:22,298 --> 00:05:24,638
Public housing sometimes uses this technology.

58
00:05:25,259 --> 00:05:28,779
So we just wanted to set up a transparent process before Medford.

59
00:05:29,299 --> 00:05:32,360
Right now in Medford, we don't have a ton of this technology.

60
00:05:32,900 --> 00:05:38,721
Maybe the thing that's the closest is the body-worn cameras, although, you know, we do have a lot of surveillance cameras in the city.

61
00:05:38,741 --> 00:05:39,661
But

62
00:05:42,382 --> 00:05:52,799
We want to be ahead of the game so that if Medford wants to purchase some of this more advanced technology that we're able to have community input into it and understand how it's being used.

63
00:05:54,409 --> 00:06:02,893
One thing that comes up a lot that I'll just mention here and then I'll turn it over to Kit is this ordinance doesn't restrict individual uses.

64
00:06:02,973 --> 00:06:05,074
This is more of a policy perspective.

65
00:06:05,114 --> 00:06:10,076
We just want to know what are we using and how, in a general sense, it will be used.

66
00:06:10,156 --> 00:06:14,718
It's not like inserting city council into every police investigation.

67
00:06:15,118 --> 00:06:15,858
That's not the point.

68
00:06:16,258 --> 00:06:18,699
It's more what are our policies for this and how it will be used.

69
00:06:19,600 --> 00:06:19,820
Great.

70
00:06:19,880 --> 00:06:20,220
Thank you.

71
00:06:22,400 --> 00:06:23,261
Yeah, thanks, Jean.

72
00:06:24,481 --> 00:06:27,823
I think that's a really great and clear overview.

73
00:06:27,843 --> 00:06:40,570
And just to add a little bit from the city council perspective and what motivated me to jump onto this ordinance project when I was first approached by Medford People Power at the start of my term.

74
00:06:42,351 --> 00:06:49,335
But first, just to color it a bit about that last point that Jean was making about what this ordinance does and doesn't do when we first started meeting on this.

75
00:06:50,395 --> 00:06:58,257
Um, you know, I got some questions from residents saying, Hey, like I have a nest camera, you know, because I get Amazon packages dropped off.

76
00:06:58,297 --> 00:06:59,357
Will this affect me?

77
00:06:59,417 --> 00:07:00,377
And the answer is no.

78
00:07:00,978 --> 00:07:03,338
Um, this is community control over public surveillance.

79
00:07:03,438 --> 00:07:10,040
It only regulates surveillance technologies or surveillance data that the city uses or owns or purchases.

80
00:07:10,680 --> 00:07:12,700
Um, so just to clear that up, cause I know it's.

81
00:07:13,600 --> 00:07:17,401
It's a lot of terms that we're not used to using in common parlance to just to draw that distinction.

82
00:07:17,441 --> 00:07:19,842
It's, um, public uses of surveillance technology.

83
00:07:21,743 --> 00:07:29,487
So as Jean was saying, there's not a ton of surveillance technology that is currently being used in Medford.

84
00:07:30,247 --> 00:07:33,989
But this ordinance was still, I think, really important to get on the books now.

85
00:07:34,009 --> 00:07:44,115
And I think that we were well positioned to take up the ordinance now, even though it's not like we're flush with all of these new and different and novel surveillance technologies, you know, for a number of reasons.

86
00:07:44,795 --> 00:08:03,740
The first reason is that I think in so many cases, we're well served by creating a mechanism for thinking through something as a community before we're inundated by it, before it's become a really big, overwhelming, urgent issue.

87
00:08:04,300 --> 00:08:24,832
to say okay like right now Medford has you know one surveillance technology that's explicitly covered by the ordinance it's still important to have a structure and say okay that's great and let's make a structure now for getting city council input into surveillance technology in general and creating a mechanism for community involvement in that process in general so that

88
00:08:25,752 --> 00:08:29,375
the next time a surveillance technology is proposed by some city agency.

89
00:08:29,395 --> 00:08:38,862
We're not scrambling to make sure that the process for considering it is transparent and is accountable and that the community has a fighting chance to know what's going on.

90
00:08:38,902 --> 00:08:39,963
We're setting that up in advance.

91
00:08:40,504 --> 00:08:48,770
And I just think for any issue, it's really important to be proactive in that way, especially when you're dealing with things that really are significant.

92
00:08:49,691 --> 00:08:53,314
And I think that that is the part that was really one of the many parts that was compelling to me.

93
00:08:54,829 --> 00:09:03,312
about an ordinance that provides a structure for regulating surveillance technology is, they're significant and kind of across many categories.

94
00:09:04,352 --> 00:09:11,655
The first one, which I think relates most clearly, tracks most clearly to our other responsibilities on the City Council is

95
00:09:12,155 --> 00:09:14,957
These technologies are really, really expensive.

96
00:09:15,598 --> 00:09:23,083
One of our existing responsibilities as a city council is to sign off on major financial commitments.

97
00:09:23,723 --> 00:09:32,109
Money papers come to us, appropriations come to us, we have the yes, no vote on the budget, you know, discretionary spending during the year comes before us and we vote on it.

98
00:09:32,750 --> 00:09:35,231
Surveillance technologies are unbelievably expensive.

99
00:09:35,331 --> 00:09:39,655
So even on that metric alone, it is consistent with the rest of our abilities to have a voice

100
00:09:40,415 --> 00:09:58,222
in the discussion of what is this big investment, you know, whether it's body-worn cameras, which were purchased before this ordinance went into effect, you know, or whatever the next surveillance technology proposed is, is this major expense going to help us, is it going to help us enough that it's worth this amount of money?

101
00:09:59,642 --> 00:10:02,203
That, you know, could easily go to any other community need.

102
00:10:02,543 --> 00:10:03,044
Is it worth it?

103
00:10:03,264 --> 00:10:07,405
And maybe it is, but we have to have a discussion about it, the same as we do with any other major expense.

104
00:10:07,985 --> 00:10:19,170
The other thing, you know, that I think undergirds all of this, and the other reason why it's really important to make sure that the conversation about whether and how these come into the community is really important is

105
00:10:20,983 --> 00:10:32,563
You know, these technologies can pose real threats to personal privacy, to civil liberties, especially to people in communities of color, marginalized populations.

106
00:10:34,485 --> 00:10:39,228
And we haven't, you know, we haven't seen that in Medford yet because we don't have a lot of surveillance technology.

107
00:10:40,108 --> 00:10:42,049
But we've seen that in other communities all over the nation.

108
00:10:42,089 --> 00:10:48,633
We've seen surveillance technologies lead to wrongful arrests, wrongful convictions.

109
00:10:48,653 --> 00:10:51,775
We've seen them exacerbate over-policing of communities of color.

110
00:10:53,456 --> 00:10:54,597
These are things that we have

111
00:10:55,417 --> 00:10:56,377
that we should be wary of.

112
00:10:56,457 --> 00:11:05,480
I think that really shores up the need for a proactive process about saying, you know, no technology is fully benevolent.

113
00:11:05,720 --> 00:11:12,322
You know, no community is immune from things that we know to be risky and complicated.

114
00:11:13,842 --> 00:11:17,923
You know, it's not like we have public agencies developing and promulgating these technologies.

115
00:11:17,964 --> 00:11:22,645
These are privately developed, and they're aggressively marketed to communities, and this ordinance

116
00:11:23,345 --> 00:11:35,592
you know, what I think it says is there's nothing special about Medford for why we need CCOPS, but there's also nothing about Medford that makes us immune to the real risks and complexities of surveillance technology.

117
00:11:35,612 --> 00:11:44,076
And that's why we wanted to try and pass this ordinance, you know, now and not wait any longer because, you know, we don't have any technology that's going away.

118
00:11:44,356 --> 00:11:45,957
We just have more technology coming in.

119
00:11:48,198 --> 00:11:49,279
Ed, was there something you wanted to add?

120
00:11:50,806 --> 00:12:00,910
Well, Kit covered it, but I did want to point out that the Boston Globe did an article about where the technologies that the Boston Police Department are employed.

121
00:12:01,770 --> 00:12:05,171
And it was predominantly in low income communities of color.

122
00:12:06,192 --> 00:12:11,074
And nationally, that is what we see is surveillance technologies are being used.

123
00:12:12,495 --> 00:12:17,960
in most vulnerable neighborhoods, often without any oversight.

124
00:12:17,980 --> 00:12:22,385
And the second piece of that is that they're often very bad.

125
00:12:23,566 --> 00:12:27,590
Facial recognition is a perfect example of they're very bad at

126
00:12:28,711 --> 00:12:38,274
working with people of color and that they don't match well, they often misidentify who is seen in the camera or who's in the photo.

127
00:12:38,834 --> 00:12:46,257
So they're overused in those communities, but they're not well created for the communities they're used in.

128
00:12:46,937 --> 00:12:47,277
That's all.

129
00:12:49,665 --> 00:12:59,169
So, while you are both speaking I was appreciating the notion of designing a community mechanism of thinking about what our process audit might look like.

130
00:13:00,090 --> 00:13:03,271
And I guess to that point I'm wondering if you might speak more more on.

131
00:13:05,612 --> 00:13:20,106
Medford People Power as an organization, and then maybe what it would look like for folks to kind of engage with this thought process, you know, in a timeline that makes sense towards, you know, what it means to drive process that can become policy in time.

132
00:13:20,126 --> 00:13:20,767
Sure.

133
00:13:23,158 --> 00:13:28,203
So Medford People Power was started in March of 2017.

134
00:13:30,025 --> 00:13:39,255
That was around when Trump was elected and started to do significant anti-immigrant policies.

135
00:13:41,317 --> 00:13:48,719
and deputized police departments to report undocumented immigrants or people they believe to be undocumented.

136
00:13:49,819 --> 00:13:53,860
So the first thing that Medford People Power did was we worked at the police department.

137
00:13:54,720 --> 00:14:04,322
The ACLU had a model policy around non-cooperation with ICE, with the immigration agency.

138
00:14:05,343 --> 00:14:06,783
Basically, our belief

139
00:14:07,543 --> 00:14:16,251
for that particular one, which we're not talking about now, but that's how we started, was just that it keeps Medford safer when immigrants feel like they can work with the police.

140
00:14:17,572 --> 00:14:20,554
And so we succeeded in getting that policy passed.

141
00:14:20,594 --> 00:14:22,936
And then the next thing we did was to work on CCOPS.

142
00:14:23,717 --> 00:14:29,822
We're a small but mighty group and would love to have more members join us.

143
00:14:30,303 --> 00:14:32,365
We meet, our meetings are open.

144
00:14:32,585 --> 00:14:33,666
We meet once a month.

145
00:14:35,103 --> 00:14:39,325
And I can get you our email so people can sign up and join us.

146
00:14:41,186 --> 00:14:47,329
You know, I have a law background and have worked on policy at the city and state level.

147
00:14:47,949 --> 00:14:48,470
And I guess.

148
00:14:49,450 --> 00:14:59,757
you know, making the, they call it making the sausage, can be kind of messy and you don't always get what you want and it does take time for CCOPS.

149
00:14:59,817 --> 00:15:01,318
We worked on this for four years.

150
00:15:02,078 --> 00:15:10,864
So some of these policy pieces aren't going to happen overnight, but then you do see results and it feels great.

151
00:15:11,464 --> 00:15:16,208
So if people want to get involved, we'd love to have them join us because

152
00:15:17,088 --> 00:15:20,670
The big thing about C Cops is it's not going to work if we're not monitoring it.

153
00:15:21,290 --> 00:15:28,314
So we need to make sure it's implemented and we need to turn out to those city council hearings when they're presenting their policies.

154
00:15:28,394 --> 00:15:45,983
So the ordinance for C Cops, it sounds like the way it would work is if the city was considering a new type of public surveillance, they would have to present this to the city council or like public input before they were able to move forward.

155
00:15:46,003 --> 00:15:46,663
Is that right?

156
00:15:48,193 --> 00:16:04,160
Yes, and I don't know if you want to take this, but Kit can talk about the particulars, but that was the aim, is that any existing, it covered, it was retroactive, it covered existing and new technology, they have to get approval from city council to use.

157
00:16:05,240 --> 00:16:08,842
So there's approval to use and then approval of how it will be used.

158
00:16:12,783 --> 00:16:13,643
Yeah, exactly.

159
00:16:13,663 --> 00:16:31,753
And just to jump in to sort of just put a little bit of concreteness to the ordinance that we passed exactly sort of like the how of that community involvement and city council involvement process is putting aside for a moment the approval of any pre-existing uses.

160
00:16:32,553 --> 00:16:38,856
You know, should a new surveillance technology be proposed by any Medford agency, by which I mean like

161
00:16:40,517 --> 00:16:47,700
school department, Medford police, any other department says like, hey, I think this would be useful for my department.

162
00:16:47,820 --> 00:16:48,740
I would like to use this.

163
00:16:50,441 --> 00:16:59,145
They then have to fulfill certain conditions before the city council, which is to put together a document, a use policy, which just says, this is what this is.

164
00:16:59,205 --> 00:17:00,205
This is what it's for.

165
00:17:00,245 --> 00:17:01,585
This is how much it would cost.

166
00:17:01,786 --> 00:17:03,786
And this is why we want to use it.

167
00:17:03,826 --> 00:17:05,087
This is how we think it would be useful.

168
00:17:06,187 --> 00:17:08,749
That goes before the City Council, we get to discuss it.

169
00:17:09,169 --> 00:17:12,972
We're holding public meetings, you know, it's often said the City Council is the public forum.

170
00:17:13,512 --> 00:17:22,538
Sometimes that feels more materially true than other times because there's, you know, often not that many people watching in, but this does provide an opportunity to say this is being discussed in public forum.

171
00:17:23,318 --> 00:17:25,880
Um, you know, those should be well publicized.

172
00:17:25,900 --> 00:17:32,005
This is people's opportunity to listen in, to know what's being proposed, to know what's being discussed.

173
00:17:32,045 --> 00:17:37,789
It becomes part of the public record so people can refer back to it and learn about it later on.

174
00:17:38,250 --> 00:17:50,058
And then the city council has an opportunity to, you know, read that document, learn, discuss with the, you know, essentially with the proponent, um, why this is being, why this is being sought.

175
00:17:50,859 --> 00:17:51,440
Um, and then

176
00:17:53,210 --> 00:18:00,373
either vote yes, we approve this use policy for the surveillance technology, or to say no, or to request modifications.

177
00:18:00,813 --> 00:18:06,795
We'll say yes if you tweak this use policy, like we think it can be used in this way, but we don't feel good about this way.

178
00:18:07,995 --> 00:18:15,658
We feel good about this scope, but we're hearing concerns from the residents about this aspect, so it's an opportunity for some revision.

179
00:18:16,658 --> 00:18:20,660
like we do in a lot of other areas, such as, you know, on ordinances or on the city budget.

180
00:18:22,180 --> 00:18:28,182
And that's the process for kind of putting it before the city council, before the surveillance technology is approved.

181
00:18:28,663 --> 00:18:34,345
And that's the mechanism for essentially, you know, inviting the community into that process via the city council.

182
00:18:34,845 --> 00:18:37,046
And then there is also some, you know, some follow up

183
00:18:37,706 --> 00:18:44,049
on the back end for sort of continuing trying to bring the use of these technologies to light and put them on the record.

184
00:18:44,989 --> 00:19:00,695
Every surveillance technology, for every surveillance technology, there has to be an annual report filed once a year, which essentially says, essentially the goal of that document is to say, here's how we said we would be using this technology.

185
00:19:00,735 --> 00:19:02,376
Here's how we said we think it would be useful.

186
00:19:02,796 --> 00:19:03,637
Here's how it matches up.

187
00:19:04,097 --> 00:19:04,777
How was it used?

188
00:19:04,857 --> 00:19:05,577
Where was it used?

189
00:19:05,637 --> 00:19:06,578
What was it used for?

190
00:19:07,498 --> 00:19:15,540
And that goes to the city council so that we can, just in a very routinized way, be saying, does this make sense?

191
00:19:15,860 --> 00:19:24,522
Are the use of these technologies, what they're being used for, how they're helping, is it matching up to the purpose that they were purchased for?

192
00:19:24,622 --> 00:19:28,103
And if there's a discrepancy, then we can investigate that and bring that to light.

193
00:19:28,163 --> 00:19:36,105
Because with anything else, if you buy, let me try to see if I can put together a really concrete example here.

194
00:19:36,945 --> 00:19:51,514
you know, if you buy a hammer, and then, you know, all the ways you're, you know, you're mounting frames on your hall is with like, you know, with screws, you're like, well, since we should do something about this hammer that we're not using, you know, you want the tool to fit the actual need, you want it to be useful.

195
00:19:52,214 --> 00:20:00,940
Again, both because these are, you know, risky technologies, we're talking about people's personal data, and because they're really expensive.

196
00:20:01,200 --> 00:20:06,443
So this is just our way of holding the city accountable to using very intense technologies responsibly.

197
00:20:08,959 --> 00:20:09,339
Thank you.

198
00:20:09,920 --> 00:20:16,665
And so it sounds like if the city were to propose a new technology, we'd hear about it in city council.

199
00:20:16,725 --> 00:20:25,673
How would like community members know to like, how could they hear about like, when this is happening, when to show up and like, you know, hear about the proposal and voice their opinions?

200
00:20:30,897 --> 00:20:34,380
They could get on our Medford People Power email list.

201
00:20:34,740 --> 00:20:36,782
So we have an email list and we

202
00:20:37,585 --> 00:20:43,747
you know, if you want to get involved, but don't feel like you can commit to meetings, you can get on our email list and we'll alert you.

203
00:20:43,767 --> 00:20:53,090
It will be posted on the City Council agenda, so those of us that read the City Council agendas closely, you would see that.

204
00:20:54,431 --> 00:21:03,094
We partnered with eight community groups across the city on this, so we would reach out to them to get them involved.

205
00:21:04,334 --> 00:21:15,238
NAACP, Mystic Valley, Safe Medford, some church groups, the Democratic City Committee also supported this.

206
00:21:15,278 --> 00:21:19,220
So we reach out to the community organizations to let them know also.

207
00:21:19,240 --> 00:21:27,763
And I have our email, which is medford.people.power at gmail.com.

208
00:21:28,084 --> 00:21:31,805
So if anyone wants to get involved, they could just email us.

209
00:21:31,825 --> 00:21:33,926
Thank you.

210
00:21:36,310 --> 00:21:44,853
So I feel like while listening to both of you speak in different ways, you both kind of touched on the intersectionality of where CCOPS could be heading.

211
00:21:44,913 --> 00:21:54,415
I feel like I heard you mention the relationship between law and surveillance and sort of race-based indicators, health-based indicators.

212
00:21:54,755 --> 00:21:56,156
I wondered if you might just

213
00:21:57,603 --> 00:22:05,640
forecast for us kind of your sense of the breadth of where this could be headed and why it's so important to build the mechanism now?

214
00:22:07,182 --> 00:22:11,223
Well, I mentioned earlier that making the sausage is sometimes ugly.

215
00:22:11,243 --> 00:22:13,744
It's like the messy process.

216
00:22:14,304 --> 00:22:22,047
So this isn't a perfect ordinance in the process of negotiating with the mayor and the police department.

217
00:22:22,167 --> 00:22:31,590
And I do wanna say that the mayor was supportive of the overall concept of C-COPs, but there were some changes made to the ordinance that we would like to fix.

218
00:22:33,232 --> 00:22:47,574
One of them is that there's a section on, you know, data, sort of the, we talked about like location data or those protected pieces of data which right now are not very well regulated.

219
00:22:48,595 --> 00:23:00,943
As far as Google can take all the phones, location data, sell it to a broker, and then there was just an article in the Globe, San Francisco Police Department purchases all of this bulk data.

220
00:23:00,963 --> 00:23:10,971
I don't want to get too complicated, but if they buy different sources of bulk data, they can actually start to identify people and figure out where they've been.

221
00:23:11,511 --> 00:23:12,712
That's not regulated at all.

222
00:23:15,319 --> 00:23:22,328
So that was excluded in this, the final moments of developing the ordinance.

223
00:23:22,868 --> 00:23:29,917
So the police department under this ordinance can purchase that data without going in front of city council.

224
00:23:31,218 --> 00:23:33,779
And that was a last minute edit by the city.

225
00:23:34,900 --> 00:23:46,145
And so we would like to change that and make any bull purchasing of privacy data, of data we would say is privacy, privacy protected data that would have to go through city council.

226
00:23:46,165 --> 00:23:47,926
Does that make sense?

227
00:23:47,946 --> 00:23:48,987
I don't know if I explained it.

228
00:23:49,027 --> 00:23:49,887
Yeah, no, thank you.

229
00:23:50,187 --> 00:24:00,292
Yeah, I think I'm just putting my head to maybe like a cultural onboarding of the notion of big data and the power that it yields without regulation, maybe.

230
00:24:00,780 --> 00:24:01,140
Right.

231
00:24:02,582 --> 00:24:19,277
The other piece and then I'll kick it into the details of some of this, but the only way the city would agree to this is if we excluded body worn cameras for, I think it's five years, so they will eventually come under this ordinance but right now they're excluded.

232
00:24:21,259 --> 00:24:36,227
And so just monitoring how body worn cameras go, whether they're actually you know the the stated purpose of for the city to get them is for accountability, you know, for the police to be accountable to the public.

233
00:24:37,989 --> 00:24:51,266
And so we just want to make sure that how they're used instead of as a surveillance tool, which has happened in other communities where it's used more as evidence in criminal cases and as a tool to surveil the public.

234
00:24:54,035 --> 00:24:54,776
Yeah, thanks, Jean.

235
00:24:54,816 --> 00:24:57,239
I think that you, I think that you put all that really well.

236
00:24:57,299 --> 00:25:06,389
And those are a lot of, I think, really important notes for people to know about kind of what to expect in the short term from the ordinance and how it got here.

237
00:25:06,409 --> 00:25:13,196
You know, I think, especially reflecting on what you just shared, I think like one of the themes of this

238
00:25:13,957 --> 00:25:20,403
of this project and other projects like it is trust but verify.

239
00:25:20,443 --> 00:25:34,696
As we were working through this ordinance over the past year and a half in committee, something that I was trying to make very clear to my colleagues and other people that we were working with was this isn't being proposed because of the people in power right now at all.

240
00:25:35,236 --> 00:25:44,258
this is not because of any particular administration, it's not because of any particular staff member, you know, who's leading what, that is, you know, that is not the point.

241
00:25:44,538 --> 00:25:51,320
We're going to see, you know, in terms of where do we go from here, you know, thinking even beyond the next five years, we don't know where we're going from here.

242
00:25:51,840 --> 00:25:57,882
We don't know who's going to be in charge of what in 10 years or 25 years, and we don't know what technologies are going to be

243
00:25:58,742 --> 00:26:03,706
developed and produced and marketed to Medford in 10 years or 25 years or 50 years.

244
00:26:03,766 --> 00:26:05,367
We just know that it's still going to be an issue.

245
00:26:05,968 --> 00:26:07,769
Surveillance technology is not going away.

246
00:26:07,789 --> 00:26:13,973
I think that we would be doing a disservice to our residents if we say, well, it'll be probably fine.

247
00:26:14,334 --> 00:26:18,096
I'm sure that nothing will come across our desks that would be that bad, so not a big deal.

248
00:26:18,437 --> 00:26:19,017
It is a big deal.

249
00:26:20,298 --> 00:26:22,480
By being proactive, we make sure that we

250
00:26:23,756 --> 00:26:27,962
gives ourselves the chance to catch things before they become a big harmful deal.

251
00:26:28,924 --> 00:26:38,878
So, you know, we know that in five years, body-worn cameras will become subject to all of the requirements of the ordinance, you know, not just the annual recording.

252
00:26:39,819 --> 00:26:44,723
And I think until then, you know, it's just a great way for constituents to remain engaged.

253
00:26:45,804 --> 00:27:01,898
And, you know, residents and city council members alike to try to remain engaged and stay in touch and try to be learning as much as we can about the use policies that are promulgated in the short term to see if any edits need to be made when they do become subject to the ordinance in five years, same as we would for any other technology.

254
00:27:02,788 --> 00:27:12,570
and to make sure, as Jean mentioned, that we are continuing to monitor this ordinance and monitor its implementation and enforcement.

255
00:27:13,410 --> 00:27:16,530
Every ordinance can be a living document to say, let's see how this is working.

256
00:27:16,991 --> 00:27:21,651
Let's see if this is doing what we need it to do because the surveillance technology is going away.

257
00:27:21,711 --> 00:27:24,392
So if there's a way to make this stronger and more protective, then we should do that.

258
00:27:24,412 --> 00:27:28,953
Thank you.

259
00:27:32,497 --> 00:27:40,800
So 50 years into the future, I think, Kit, while you were talking, I'm wondering about whether there's sort of a CCOPS-based youth energy.

260
00:27:41,160 --> 00:27:51,885
And I think my head is specifically going to app-based data and, you know, the extent to which we kind of all maybe use apps, but maybe young folks in particular.

261
00:27:52,245 --> 00:27:56,967
And there's a lot there that can be weaponized in different spaces.

262
00:27:57,067 --> 00:28:00,388
So if you have any thoughts, or Jean, if you have thoughts, thank you.

263
00:28:07,277 --> 00:28:07,997
You can go ahead, Kit.

264
00:28:09,638 --> 00:28:10,659
Okay, sure.

265
00:28:12,300 --> 00:28:21,585
I think that, yeah, I mean, I think the question overall makes me think of, you know, kind of how hard it is to know what's coming down the pike in the future.

266
00:28:22,646 --> 00:28:28,809
And certainly, like, there's a million branches to be like thinking and speculating about, you know, and you mentioned apps.

267
00:28:29,269 --> 00:28:29,990
I mean, I know there was a

268
00:28:30,810 --> 00:28:57,208
very large and ongoing national conversation about data privacy and security related to TikTok on the national scale in terms of national level security concern, which is just one illustrative example of how any seemingly innocuous thing can have this underbelly where it's something that we really have to be thinking about in terms of privacy and security at the personal, local, state, national level.

269
00:29:00,747 --> 00:29:09,834
you know, that very quickly gets outside of the jurisdiction of what me and my city council colleagues have the ability to, you know, write policy about.

270
00:29:10,434 --> 00:29:16,579
But I think it shores up the point that, you know, this issue is going to be advancing on all levels.

271
00:29:17,400 --> 00:29:25,126
And I think that was a big part of the motivation for me to spend so much of my first term working on this ordinance, because we were so lacking in regulation.

272
00:29:25,626 --> 00:29:32,068
As Jean mentioned earlier, at the federal and state levels, we have to do all that we can.

273
00:29:32,088 --> 00:29:42,912
At the local level, we should be using all the tools in the tool box so that there are these big gaps in regulation at every level, but the ones that we can affect, we should be doing that.

274
00:29:46,773 --> 00:29:49,274
I just had a follow-up to that, but I lost my train of thought.

275
00:29:51,194 --> 00:29:52,515
I'll come back to it.

276
00:29:52,795 --> 00:29:53,155
No problem.

277
00:29:54,669 --> 00:30:01,843
If I could jump in and just I mean I think it's all it's an issue now there is a state.

278
00:30:02,790 --> 00:30:12,672
bill the ACLU is promoting called the Location Shield Act, which would shield from government location data.

279
00:30:13,892 --> 00:30:22,413
And the reason this is important is you see it being used right now in states that have outlawed abortion.

280
00:30:23,273 --> 00:30:28,734
They're using it to track people who either go in state or out of state to seek an abortion.

281
00:30:28,834 --> 00:30:31,755
And so it's,

282
00:30:32,695 --> 00:30:40,023
Those at that app based data location data is being used in some states now and there is this bill is called Location Shield Act.

283
00:30:40,484 --> 00:30:45,209
The ACLU is promoting to protect that data in Massachusetts.

284
00:30:46,170 --> 00:30:48,412
Yeah, I like the overlap with like.

285
00:30:49,542 --> 00:31:00,130
of like equity in sort of this type of regulation, right, where you're saying like we have these technologies, we're not exactly sure how they'll operate, but we are sort of sure that they will affect different people differently.

286
00:31:00,150 --> 00:31:08,696
And I think it sounds like this ordinance helps us to be sort of like responsive to these issues rather than reactive.

287
00:31:08,736 --> 00:31:15,080
So we have a plan in place for like what happens when these sort of come to the city and how we kind of want to respond to them.

288
00:31:15,100 --> 00:31:17,522
Kit, did you have something you wanted to add?

289
00:31:18,562 --> 00:31:19,582
Yeah, thank you.

290
00:31:19,622 --> 00:31:39,407
I think that's just, I think that if there's one thing that I want to leave people with, it's sort of, you know, for folks who like aren't, who don't go into this conversation familiar with surveillance technology and knowing, you know, why it's something to, you know, be kind of reasonably wary about and be building a process around.

291
00:31:39,467 --> 00:31:41,488
It's exactly the point that you just made, Danielle.

292
00:31:43,768 --> 00:31:45,669
You know, and again, to kind of try and

293
00:31:46,513 --> 00:31:55,556
search for metaphors as I like to do, I think it's very hard for humans in general to conceptualize threats that are already occurring.

294
00:31:55,756 --> 00:32:04,899
We see this in climate change, but as a more recent example, when the COVID-19 pandemic started in 2020, we weren't repaired.

295
00:32:05,319 --> 00:32:09,400
We didn't have the stockpile of the things that we would have needed at the time because we didn't know that we would need them.

296
00:32:10,738 --> 00:32:22,106
We were able to belatedly build up those stocks of ventilators and N95s, and now we're trying to make our health system more resilient to future shocks.

297
00:32:23,367 --> 00:32:25,188
But we weren't ready when it happened.

298
00:32:25,329 --> 00:32:28,571
Of course, you can't be ready for every unpredictable thing.

299
00:32:28,851 --> 00:32:36,236
But in this case, we can reasonably predict that this is something that we need to have a catching mechanism for.

300
00:32:38,696 --> 00:32:42,499
because of the trajectory that the proliferation of surveillance technologies are already around.

301
00:32:42,519 --> 00:32:59,531
And I think this is true of sort of any technological arc, but it's especially true, you know, it's as true of surveillance technology, and it's very impactful for individual people and, you know, societies of any size, which is that, you know, the pace of evolution for privately developed

302
00:33:00,311 --> 00:33:06,576
technologies is going to far, far, far outstrip the pace of any level of government to regulate them.

303
00:33:07,156 --> 00:33:23,868
This is why we've had the ability to implement facial recognition technology in cities and states for years, and our governments are still trying to hash out these facial recognition regulations on the state level.

304
00:33:24,669 --> 00:33:25,570
We're always going to be behind.

305
00:33:26,714 --> 00:33:31,197
So we have to really swim against that tide and say, no, we're being proactive.

306
00:33:31,657 --> 00:33:32,518
This is not naive.

307
00:33:32,818 --> 00:33:36,961
It would be naive to think that this is not going to be an issue that we have to prepare ourselves for as best as we can.

308
00:33:38,922 --> 00:33:39,342
Thank you.

309
00:33:40,243 --> 00:33:40,643
Well, thank you.

310
00:33:40,663 --> 00:33:44,886
This has been a really comprehensive view of CCOPS and all of its impacts.

311
00:33:45,486 --> 00:33:48,648
I wonder if there's anything else that either of you want to mention before we wrap up.

312
00:33:52,361 --> 00:33:56,764
I just want to put the plug in that we love to have more people join us with Medford People Power.

313
00:33:57,945 --> 00:33:58,706
We're a great group.

314
00:33:58,826 --> 00:34:03,049
We support each other, and it's just a really fun group.

315
00:34:04,610 --> 00:34:10,314
So again, if you want to join us, it's medford.people.power at gmail.com.

316
00:34:11,155 --> 00:34:14,918
And you can either just get on our email list or join us at meetings.

317
00:34:15,078 --> 00:34:16,058
So we'd love to see you.

318
00:34:17,339 --> 00:34:17,560
Great.

319
00:34:17,820 --> 00:34:18,040
Thank you.

320
00:34:19,333 --> 00:34:22,194
And I will corroborate that Medford People Power is great.

321
00:34:22,694 --> 00:34:26,655
I am so grateful to them for working with me on this ordinance.

322
00:34:27,476 --> 00:34:33,097
Over the past year and a half, they put in a lot of many, many months of hard work on it before I was ever elected.

323
00:34:33,798 --> 00:34:39,179
And I'm really glad to be able to work with them on privacy and civil liberties in Medford.

324
00:34:40,620 --> 00:34:40,900
Awesome.

325
00:34:41,400 --> 00:34:42,320
Well, thank you both.

326
00:34:44,121 --> 00:34:44,481
Thank you.

327
00:34:44,501 --> 00:34:47,022
Yeah, thank you.

328
00:34:56,213 --> 00:34:58,175
Thanks so much for listening to today's episode.

329
00:34:58,635 --> 00:35:03,340
The Medford Bites podcast is produced and moderated by Danielle Balacca and Shelly Keshaman.

330
00:35:04,000 --> 00:35:05,542
Music is made by Hendrik Irenys.

331
00:35:06,483 --> 00:35:08,604
We'd love to hear what you think about the podcast.

332
00:35:09,025 --> 00:35:15,711
You can reach out to us by email at medfordpod at gmail.com, or you can rate and review the podcast on Apple Podcasts.

333
00:35:16,532 --> 00:35:17,593
Thanks so much for listening.

334
00:35:25,629 --> 00:35:27,113
Guys, what's the name of the podcast?

335
00:35:27,254 --> 00:35:28,096
Never Bites.

336
00:35:28,317 --> 00:35:29,962
Never Bites.

337
00:35:30,002 --> 00:35:30,423
Good job.

